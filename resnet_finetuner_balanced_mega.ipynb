{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2421c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsorokin\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\rsorokin\\Anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Global seed set to 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(100)\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2083acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrommium\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341d0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMGS_PATH = '../prepare_datasets/data_add_all_balanced/train/'\n",
    "TRAIN_ADD_IMGS_PATH = '../prepare_datasets/data_add_all_balanced/train_add/'\n",
    "TRAIN_ALL_IMGS_PATH = '../prepare_datasets/data_add_all_balanced/train_all_add/'\n",
    "\n",
    "\n",
    "TRAIN_DF_PATH = '../prepare_datasets/data_add_all_balanced/train_clear.csv'\n",
    "TRAIN_ADD_DF_PATH = '../prepare_datasets/data_add_all_balanced/train_add.csv'\n",
    "TRAIN_ALL_DF_PATH = '../prepare_datasets/data_add_all_balanced/train_all_add.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f41d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((384,384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((384,384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113c7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetTrain(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # достаем имя изображения и ее лейбл\n",
    "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
    "\n",
    "        # читаем картинку. read the image\n",
    "        image = cv2.imread(f\"{TRAIN_ALL_IMGS_PATH}/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # преобразуем, если нужно. transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3842bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetVal(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # достаем имя изображения и ее лейбл\n",
    "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
    "\n",
    "        # читаем картинку. read the image\n",
    "        image = cv2.imread(f\"{TRAIN_ALL_IMGS_PATH}/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # преобразуем, если нужно. transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91dcd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFinetuner(pl.LightningModule):\n",
    "    def __init__(self, resnet_version, train_dataset, val_dataset, batch_size, optimizer, optimizer_params, transfer=True):\n",
    "        super(ResNetFinetuner, self).__init__()\n",
    "        \n",
    "        resnets = {\n",
    "            18: models.resnet18, 34: models.resnet34,\n",
    "            50: models.resnet50, 101: models.resnet101,\n",
    "        }\n",
    "        optimizers = {'adam': torch.optim.Adam}\n",
    "\n",
    "        self.resnet_model = resnets[resnet_version](pretrained=True)\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.optimizer_params = optimizer_params\n",
    "        self.optimizer = optimizers[optimizer]\n",
    "        self.batch_size = batch_size\n",
    "        linear_size = list(self.resnet_model.children())[-1].in_features\n",
    "        self.resnet_model.fc = torch.nn.Linear(linear_size, 3)\n",
    "        \n",
    "        if transfer:\n",
    "            for child in list(self.resnet_model.children())[:-1]:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.train_f1 = torchmetrics.F1Score(3)\n",
    "        self.val_f1 = torchmetrics.F1Score(3)\n",
    "        self.train_acc = torchmetrics.Accuracy(3)\n",
    "        self.val_acc = torchmetrics.Accuracy(3)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.resnet_model(X)\n",
    "        return F.softmax(X, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "        self.log('train/loss', loss, on_epoch=True)\n",
    "        self.train_f1(preds, y)\n",
    "        self.train_acc(preds, y)\n",
    "        self.log('train/f1', self.train_f1, on_epoch=True)\n",
    "        self.log('train/acc', self.train_acc, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        self.val_f1(preds, y)\n",
    "        self.val_acc(preds, y)\n",
    "        self.log(\"validation/loss_epoch\", loss)\n",
    "        self.log(\"validation/f1_epoch\", self.val_f1)\n",
    "        self.log(\"validation/acc_epoch\", self.val_acc)\n",
    "        return logits\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "        self.logger.experiment.log(\n",
    "            {\"validation/logits\": wandb.Histogram(flattened_logits.cpu()),\n",
    "             \"global_step\": self.global_step}, commit=False\n",
    "        )\n",
    "\n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         x, y, _ = batch\n",
    "#         preds = self(x)\n",
    "#         loss = F.cross_entropy(preds, y)\n",
    "#         self.test_f1(preds, y)\n",
    "#         self.log(\"test/loss_epoch\", loss, on_step=False, on_epoch=True)\n",
    "#         self.log(\"test/f1_epoch\", self.test_f1, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer([p for p in self.parameters() if p.requires_grad], **self.optimizer_params)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = torch.utils.data.DataLoader(self.train_dataset, \n",
    "                                                   batch_size=self.batch_size, \n",
    "                                                  shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "        return val_loader\n",
    "    \n",
    "#     def test_dataloader(self):\n",
    "#         train_loader = torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "#         return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c56cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLogger(pl.Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "        self.val_imgs = self.val_imgs[:num_samples]\n",
    "        self.val_labels = self.val_labels[:num_samples]\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\": [wandb.Image(x, caption=f\"Pred: {pred}, Label: {y}\") for x, pred, y in zip(val_imgs, preds, self.val_labels)],\n",
    "            \"global_step\": trainer.global_step\n",
    "        }, commit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e76af9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    308\n",
       "2.0    143\n",
       "0.0     92\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(TRAIN_DF_PATH)\n",
    "data_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30b0b81e",
   "metadata": {},
   "source": [
    "_, valid_df = train_test_split(data_df, test_size=0.4, random_state=43, stratify=data_df['class'])\n",
    "train_df = pd.read_csv(TRAIN_ALL_DF_PATH)\n",
    "train_df = train_df[~train_df['ID_img'].isin(list(valid_df['ID_img']))]\n",
    "\n",
    "train_dataset = ImageDatasetTrain(train_df, train_transform)\n",
    "valid_dataset = ImageDatasetVal(valid_df, valid_transform)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0691918e",
   "metadata": {},
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4a8f7b4",
   "metadata": {},
   "source": [
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3f012df",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "wandb_logger = WandbLogger(project=\"lit-wandb\")\n",
    "optimizer_params = {'lr': 0.001}\n",
    "resnet_finetuner = ResNetFinetuner(resnet_version=50, \n",
    "                                   train_dataset=train_dataset, \n",
    "                                   val_dataset=valid_dataset, \n",
    "                                   batch_size=32, \n",
    "                                   optimizer='adam', \n",
    "                                   optimizer_params=optimizer_params, \n",
    "                                   transfer=True)\n",
    "\n",
    "samples = next(iter(resnet_finetuner.val_dataloader()))\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,    # W&B integration\n",
    "    log_every_n_steps=50,   # set the logging frequency\n",
    "    gpus=-1,                # use all GPUs\n",
    "    max_epochs=10,           # number of epochs\n",
    "    deterministic=True,     # keep it deterministic\n",
    "    callbacks=[ImageLogger(samples)] # see Callbacks section\n",
    "    )   \n",
    "trainer.fit(resnet_finetuner)\n",
    "#trainer.test(test_dataloaders=resnet_finetuner.test_dataloader())\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5f0d6d0",
   "metadata": {},
   "source": [
    "best epoch no 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd5687",
   "metadata": {},
   "source": [
    "# train full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77f870a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, valid_df = train_test_split(data_df, test_size=0.2, random_state=43, stratify=data_df['class'])\n",
    "train_df = pd.read_csv(TRAIN_ALL_DF_PATH)\n",
    "\n",
    "train_dataset = ImageDatasetTrain(train_df, train_transform)\n",
    "valid_dataset = ImageDatasetVal(valid_df, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73a076a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.20 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\rsorokin\\Documents\\presales\\garbage_containers\\hacks-ai-ufa\\notebooks\\wandb\\run-20220704_034848-qub8egn8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chrommium/lit-wandb/runs/qub8egn8\" target=\"_blank\">fanciful-firefly-50</a></strong> to <a href=\"https://wandb.ai/chrommium/lit-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type     | Params\n",
      "------------------------------------------\n",
      "0 | resnet_model | ResNet   | 23.5 M\n",
      "1 | train_f1     | F1Score  | 0     \n",
      "2 | val_f1       | F1Score  | 0     \n",
      "3 | train_acc    | Accuracy | 0     \n",
      "4 | val_acc      | Accuracy | 0     \n",
      "------------------------------------------\n",
      "6.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.057    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsorokin\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 100\n",
      "C:\\Users\\rsorokin\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f7df5a5c974fd8bc43930dd763d1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='27.916 MB of 27.916 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▃▃▃▆▆▆███</td></tr><tr><td>global_step</td><td>▁▃▄▆█</td></tr><tr><td>train/acc_epoch</td><td>▁▆▇█</td></tr><tr><td>train/acc_step</td><td>▄▂▁█</td></tr><tr><td>train/f1_epoch</td><td>▁▆▇█</td></tr><tr><td>train/f1_step</td><td>▄▂▁█</td></tr><tr><td>train/loss_epoch</td><td>█▃▁▁</td></tr><tr><td>train/loss_step</td><td>█▇▇▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▃▃▃▅▆▆▇██</td></tr><tr><td>validation/acc_epoch</td><td>▁▄█▄</td></tr><tr><td>validation/f1_epoch</td><td>▁▄█▄</td></tr><tr><td>validation/loss_epoch</td><td>█▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>global_step</td><td>215</td></tr><tr><td>train/acc_epoch</td><td>0.90557</td></tr><tr><td>train/acc_step</td><td>1.0</td></tr><tr><td>train/f1_epoch</td><td>0.90557</td></tr><tr><td>train/f1_step</td><td>1.0</td></tr><tr><td>train/loss_epoch</td><td>0.67126</td></tr><tr><td>train/loss_step</td><td>0.60478</td></tr><tr><td>trainer/global_step</td><td>215</td></tr><tr><td>validation/acc_epoch</td><td>0.87156</td></tr><tr><td>validation/f1_epoch</td><td>0.87156</td></tr><tr><td>validation/loss_epoch</td><td>0.69788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-firefly-50</strong>: <a href=\"https://wandb.ai/chrommium/lit-wandb/runs/qub8egn8\" target=\"_blank\">https://wandb.ai/chrommium/lit-wandb/runs/qub8egn8</a><br/>Synced 6 W&B file(s), 160 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220704_034848-qub8egn8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=\"lit-wandb\")\n",
    "optimizer_params = {'lr': 0.001}\n",
    "resnet_finetuner = ResNetFinetuner(resnet_version=50, \n",
    "                                   train_dataset=train_dataset, \n",
    "                                   val_dataset=valid_dataset, \n",
    "                                   batch_size=32, \n",
    "                                   optimizer='adam', \n",
    "                                   optimizer_params=optimizer_params, \n",
    "                                   transfer=True)\n",
    "\n",
    "\n",
    "\n",
    "samples = next(iter(resnet_finetuner.val_dataloader()))\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,    # W&B integration\n",
    "    log_every_n_steps=50,   # set the logging frequency\n",
    "    gpus=-1,                # use all GPUs\n",
    "    max_epochs=3,           # number of epochs\n",
    "    deterministic=True,     # keep it deterministic\n",
    "    callbacks=[ImageLogger(samples)] # see Callbacks section\n",
    "    )   \n",
    "trainer.fit(resnet_finetuner)\n",
    "#trainer.test(test_dataloaders=resnet_finetuner.test_dataloader())\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9311610",
   "metadata": {},
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30c0fb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34020749806_42065966214_42113475048_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80128313599_98196458454_79029076007_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17820331238_48919943775_53688855463_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70492442702_21083599816_22777758696_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94790217016_17108156014_60668676818_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>60879177998_15763718934_82574532042_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11758169966_65799840524_72283028069_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>9259096884_2251720133_44072689872_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>37732252922_9265441355_19052721018_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>26230096975_1198032682_52245678077_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ID_img\n",
       "0    34020749806_42065966214_42113475048_2\n",
       "1    80128313599_98196458454_79029076007_8\n",
       "2    17820331238_48919943775_53688855463_7\n",
       "3    70492442702_21083599816_22777758696_0\n",
       "4    94790217016_17108156014_60668676818_2\n",
       "..                                     ...\n",
       "220  60879177998_15763718934_82574532042_2\n",
       "221  11758169966_65799840524_72283028069_1\n",
       "222    9259096884_2251720133_44072689872_8\n",
       "223   37732252922_9265441355_19052721018_3\n",
       "224   26230096975_1198032682_52245678077_3\n",
       "\n",
       "[225 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../sample_solution.csv\")\n",
    "test_df = test_df.drop([\"class\"], axis = 1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaa46a38",
   "metadata": {},
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f20e728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMGS_PATH = '../test_dataset_test/'\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data_df.iloc[idx]['ID_img']\n",
    "        \n",
    "        # читаем картинку\n",
    "        image = cv2.imread(f\"{TEST_IMGS_PATH}/{image_name}.jpg\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "#         visualize(image)\n",
    "        \n",
    "        # преобразуем, если нужно\n",
    "        if self.transform:\n",
    "#             image = self.transform(image=image)['image']\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c141dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestImageDataset(test_df, valid_transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b718f668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:53<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "resnet_finetuner.eval()\n",
    "predicts = []\n",
    "\n",
    "for imgs in tqdm(test_loader):\n",
    "    \n",
    "    imgs = imgs\n",
    "    pred = resnet_finetuner(imgs)\n",
    "\n",
    "    for class_obj in pred:\n",
    "        index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
    "        predicts.append(index)\n",
    "#         print(index)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb382625",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class'] = predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd8d7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./submit_resnet_balanced_6.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ffa5a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34020749806_42065966214_42113475048_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80128313599_98196458454_79029076007_8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17820331238_48919943775_53688855463_7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70492442702_21083599816_22777758696_0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94790217016_17108156014_60668676818_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>60879177998_15763718934_82574532042_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11758169966_65799840524_72283028069_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>9259096884_2251720133_44072689872_8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>37732252922_9265441355_19052721018_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>26230096975_1198032682_52245678077_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ID_img  class\n",
       "0    34020749806_42065966214_42113475048_2      2\n",
       "1    80128313599_98196458454_79029076007_8      1\n",
       "2    17820331238_48919943775_53688855463_7      2\n",
       "3    70492442702_21083599816_22777758696_0      2\n",
       "4    94790217016_17108156014_60668676818_2      2\n",
       "..                                     ...    ...\n",
       "220  60879177998_15763718934_82574532042_2      2\n",
       "221  11758169966_65799840524_72283028069_1      1\n",
       "222    9259096884_2251720133_44072689872_8      0\n",
       "223   37732252922_9265441355_19052721018_3      1\n",
       "224   26230096975_1198032682_52245678077_3      1\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3b33c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.573333\n",
       "2    0.235556\n",
       "0    0.191111\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a25d16fa",
   "metadata": {},
   "source": [
    "all\n",
    "1    0.622222\n",
    "0    0.200000\n",
    "2    0.177778"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dea8153",
   "metadata": {},
   "source": [
    "train no val\n",
    "1    0.546667\n",
    "2    0.244444\n",
    "0    0.208889"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c82b170c",
   "metadata": {},
   "source": [
    "original\n",
    "1.0    0.537753\n",
    "2.0    0.274401\n",
    "0.0    0.187845"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
